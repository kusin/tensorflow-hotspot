{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmEp_gntlAX_"
   },
   "source": [
    "### Hyperparameter GridSearchCV LSTM-RNN Percobaan 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variabel Terikat : Titik Panas\n",
    "- Variabel Bebas : Curah Hujan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aFdF9w2TlAYC"
   },
   "outputs": [],
   "source": [
    "# pustaka untuk manipulasi data\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "\n",
    "# pustaka untuk waktu komputasi\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Pustaka untuk visualisasi data\n",
    "import seaborn as sns # Visualization\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Pustaka untuk membuat data latih dan data uji.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Pustaka untuk membuat model prediksi LSTM-RNN\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "\n",
    "# Early stoping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Pustaka untuk  evaluasi model prediksi\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set waktu komputasi\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QO6BLIJxlAYC"
   },
   "outputs": [],
   "source": [
    "# membaca dataset\n",
    "dataset = read_excel(\"dataset/dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_X0C84vZlAYD"
   },
   "outputs": [],
   "source": [
    "# set index tanggal\n",
    "dataset = dataset.set_index(\"tanggal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1626258920272,
     "user": {
      "displayName": "colab aji",
      "photoUrl": "",
      "userId": "15648518280582116117"
     },
     "user_tz": -420
    },
    "id": "ex6mK9NwlAYD",
    "outputId": "f3a673bb-ad4a-4809-96d5-3bb8c8829b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 240 entries, 2001-01-31 to 2020-12-31\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   sst             240 non-null    float64\n",
      " 1   soi             240 non-null    float64\n",
      " 2   oni             240 non-null    float64\n",
      " 3   curah_hujan     240 non-null    float64\n",
      " 4   hotspot_sumsel  240 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 11.2 KB\n"
     ]
    }
   ],
   "source": [
    "# set informasi dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1626258922893,
     "user": {
      "displayName": "colab aji",
      "photoUrl": "",
      "userId": "15648518280582116117"
     },
     "user_tz": -420
    },
    "id": "-tCG5W3UlAYE",
    "outputId": "6ddd11f7-e325-4134-e0bf-fbf164eeef54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             sst  soi   oni  curah_hujan  hotspot_sumsel\n",
      "tanggal                                                 \n",
      "2001-01-31 -0.76  1.0 -0.68   418.600006               3\n",
      "2001-02-28 -0.56  1.7 -0.52   295.399994               5\n",
      "2001-03-31 -0.37  0.9 -0.44   360.600006              10\n",
      "2001-04-30 -0.56  0.2 -0.34   403.700012              20\n",
      "2001-05-31 -0.46 -0.5 -0.25   116.900002              39\n"
     ]
    }
   ],
   "source": [
    "# menampilkan dataset\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHygYC21lAYF"
   },
   "source": [
    "### Studi kasus wilayah Sumatra Selatan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NLHR0cBblAYG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 240 entries, 2001-01-31 to 2020-12-31\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   hotspot_sumsel  240 non-null    int64  \n",
      " 1   curah_hujan     240 non-null    float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 5.6 KB\n"
     ]
    }
   ],
   "source": [
    "# memilih area studi\n",
    "df_sumsel = dataset[[\"hotspot_sumsel\", \"curah_hujan\"]]\n",
    "df_sumsel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1626258927759,
     "user": {
      "displayName": "colab aji",
      "photoUrl": "",
      "userId": "15648518280582116117"
     },
     "user_tz": -420
    },
    "id": "NDmtn18olAYG",
    "outputId": "81155b7f-8f28-4380-c9d5-305d2769609c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            hotspot_sumsel  curah_hujan\n",
      "tanggal                                \n",
      "2001-01-31               3   418.600006\n",
      "2001-02-28               5   295.399994\n",
      "2001-03-31              10   360.600006\n",
      "2001-04-30              20   403.700012\n",
      "2001-05-31              39   116.900002\n"
     ]
    }
   ],
   "source": [
    "print(df_sumsel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lkvpA74UlAYH"
   },
   "outputs": [],
   "source": [
    "# ensure all data is float\n",
    "values = df_sumsel.values\n",
    "values = values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChnwwI0tlAYH"
   },
   "source": [
    "### Normalisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Fbrm4QrllAYH"
   },
   "outputs": [],
   "source": [
    "# membuat fungsi max-min scaler\n",
    "# menggunakan pustaka scikit-learn\n",
    "def normalisasi_max_min(df):\n",
    "    # memanggil fungsi max min scaler\n",
    "    hasil = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "    \n",
    "    # proses max min scaler\n",
    "    hasil = hasil.fit_transform(df)\n",
    "    \n",
    "    # pengembalian nilai\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.999723,  0.549573],\n",
       "       [-0.999445,  0.082464],\n",
       "       [-0.998751,  0.329668],\n",
       "       [-0.997364,  0.493081],\n",
       "       [-0.994728, -0.594313]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(scaled[:5],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGGUCbtxlAYI"
   },
   "source": [
    "### Normalisasi dan Supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MS2tmB8llAYJ"
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    \n",
    "    # return value\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sO4ef4_dlAYJ"
   },
   "outputs": [],
   "source": [
    "# supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rwM0hrEJlAYJ"
   },
   "outputs": [],
   "source": [
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[3]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1626258939582,
     "user": {
      "displayName": "colab aji",
      "photoUrl": "",
      "userId": "15648518280582116117"
     },
     "user_tz": -420
    },
    "id": "e7cBI6cjlAYJ",
    "outputId": "d26c9baa-7d8f-40b8-a70f-3077ff3eae72"
   },
   "outputs": [],
   "source": [
    "values = reframed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)   var1(t)\n",
      "1  -0.999723   0.549573 -0.999445\n",
      "2  -0.999445   0.082464 -0.998751\n",
      "3  -0.998751   0.329668 -0.997364\n",
      "4  -0.997364   0.493081 -0.994728\n",
      "5  -0.994728  -0.594313 -0.999029\n"
     ]
    }
   ],
   "source": [
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzdHWPJBlAYK"
   },
   "source": [
    "### Data latih dan Data uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "112zwkjllAYK"
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(values) * 0.8)\n",
    "test_size = len(values) - train_size\n",
    "train, test = values[0:train_size,:], values[train_size:len(values),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZgWternzlAYK"
   },
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CrpRb-ZGlAYK"
   },
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1626258949398,
     "user": {
      "displayName": "colab aji",
      "photoUrl": "",
      "userId": "15648518280582116117"
     },
     "user_tz": -420
    },
    "id": "cGk1fqY1lAYK",
    "outputId": "2e69741d-7616-4375-8f91-c4cdb2c34487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 1, 2) (191,) (48, 1, 2) (48,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter GridSearchCV LTSM-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasRegressor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.wrappers'"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'neurons' : [10],\n",
    "              'activation' : ['sigmoid', 'tanh', 'relu', 'selu', 'elu', 'softplus'],\n",
    "              'optimizer' : ['adam', 'adamax', 'rmsprop', 'sgd'],\n",
    "              'dropout_rate' : [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "              'epochs' : [2000],\n",
    "              'batch_size' : [4, 8, 16, 32, 64],\n",
    "              'verbose' : [0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = parameters.keys()\n",
    "values = (parameters[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "print(len(combinations), str('kombinasi hyperparameter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(neurons='', activation='', optimizer='', dropout_rate=''):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # design network\n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(units=neurons, activation=activation, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    grid_model.add(Dropout(dropout_rate))\n",
    "    grid_model.add(Dense(1))\n",
    "\n",
    "    # model compile\n",
    "    grid_model.compile(loss='mae', optimizer=optimizer)\n",
    "    \n",
    "    # return value\n",
    "    return grid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = KerasRegressor(build_fn=build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=grid_model, param_grid=parameters, n_jobs=-1, cv=2, scoring= 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best parameters: %f using %s\\n\" % (grid_search.best_score_, grid_search.best_params_))\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"score\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by=\"score\", ascending=False).to_csv('gridsearch_percobaan2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluasi Model LSTM-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set akhir waktu komputasi \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses menghitung waktu komputasi\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hasil waktu komputasi\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm-rnn-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
