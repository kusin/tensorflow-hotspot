{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-RNN Sumatera Selatan Percobaan 3\n",
    "- Titik Panas diperngaruhi oleh ENSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library manipulation dataset\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from pandas import read_excel\n",
    "\n",
    "# library manipulation array\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from numpy import array\n",
    "\n",
    "# library configuration date and time\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# library data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# library analysis acf and pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# library normalize data with max-min algorithm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# library algorithm lstm-rnn with keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import RNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Early stoping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# library evaluation model\n",
    "from math import sqrt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set waktu komputasi\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membaca dataset\n",
    "dataset = read_excel(\"dataset/dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index tanggal\n",
    "dataset = dataset.set_index(\"tanggal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studi Kasus Sumatera Selatan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memilih area studi\n",
    "df_sumsel = dataset[[\"hotspot_sumsel\", \"sst\", \"soi\"]]\n",
    "df_sumsel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sumsel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all data is float\n",
    "values = df_sumsel.values\n",
    "values = values.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(scaled[:5],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    \n",
    "    # return value\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[4,5]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = reframed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data latih dan Data Uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(values) * 0.8)\n",
    "test_size = len(values) - train_size\n",
    "train, test = values[0:train_size,:], values[train_size:len(values),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check data train, for result supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_X = pd.DataFrame(train_X)\n",
    "temp_train_y = pd.DataFrame(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = pd.concat([temp_train_X, temp_train_y], axis=1)\n",
    "hasil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check data test, for result supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test_X = pd.DataFrame(test_X)\n",
    "temp_test_y = pd.DataFrame(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = pd.concat([temp_test_X, temp_test_y], axis=1)\n",
    "hasil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reshape input for samples, time steps, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediksi LSTM-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network grid serach\n",
    "model = Sequential()\n",
    "\n",
    "# First LSTM layer with Dropout regularisation\n",
    "model.add(\n",
    "    LSTM(\n",
    "        units=10,\n",
    "        activation='elu',\n",
    "        input_shape=(train_X.shape[1], train_X.shape[2])\n",
    "    )\n",
    ")\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "# The output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compiling model the LSTM-RNN\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='mae',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.MeanAbsoluteError(),\n",
    "        tf.keras.metrics.MeanSquaredError(),\n",
    "        tf.keras.metrics.RootMeanSquaredError()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=2000, batch_size=16,\n",
    "                    validation_data=(test_X, test_y),\n",
    "                    verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(history.history['loss'], color=\"tab:blue\", label=\"train\", linewidth=1.5)\n",
    "ax.plot(history.history['val_loss'], color=\"tab:orange\", label=\"test\", linewidth=1.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"Grafik Loss Function\", fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. make predictions\n",
    "predictions = model.predict(test_X, verbose=0)\n",
    "print(predictions[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluasi Model LSTM-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(train_X, train_y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_X, test_y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(test_y, predictions)\n",
    "print('Test MAE: %.4f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test_y, predictions)\n",
    "print('Test MSE: %.4f' % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(test_y , predictions))\n",
    "print('Test RMSE: %.4f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- korelasi dan signifikansi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = np.stack((test_y.reshape(-1),predictions.reshape(-1)),axis=1)\n",
    "hasil = pd.DataFrame(hasil, columns = ['data_aktual','prediksi'])\n",
    "hasil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sc\n",
    "r, p = sc.pearsonr(hasil[\"data_aktual\"], hasil[\"prediksi\"])\n",
    "print(\"korelasi data akual dengan hasil prediksi\" +\" {:.4f} \".format(r)+ \"dengan signifikansi\" +\" {:.4f} \".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Waktu komputasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set akhir waktu komputasi \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses menghitung waktu komputasi\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hasil waktu komputasi\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi hasil prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate urutan data sesuai panjang datanya\n",
    "x = pd.date_range(start=\"2017-01-01\", periods=len(test_y), freq='MS')\n",
    "\n",
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(x, test_y, color=\"tab:blue\", label=\"data aktual\", linewidth=2.5)\n",
    "ax.plot(x, predictions, color=\"tab:red\", label=\"hasil prediksi\", linewidth=2.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Inverse Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumsel = np.array(dataset[\"hotspot_sumsel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df_sumsel = scaler.fit_transform(df_sumsel.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse value test predictions\n",
    "testPredictions = scaler.inverse_transform(predictions)\n",
    "testActual = scaler.inverse_transform(np.array(test_y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate urutan data sesuai panjang datanya\n",
    "x = pd.date_range(start=\"2017-01-01\", periods=len(test_y), freq='MS')\n",
    "\n",
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(x, testActual, color=\"tab:blue\", label=\"actual data\", linewidth=2.5)\n",
    "ax.plot(x, testPredictions, color=\"tab:red\", label=\"prediction data\", linewidth=2.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  shift test predictions for plotting\n",
    "testPredictionsPlot = np.empty_like(df_sumsel)\n",
    "testPredictionsPlot[:, :] = np.nan\n",
    "testPredictionsPlot[(len(dataset) - testPredictions.shape[0]):len(dataset), :] = testPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(dataset.index.values, scaler.inverse_transform(df_sumsel), color=\"tab:blue\", label=\"actual data\", linewidth=2)\n",
    "ax.plot(dataset.index.values, testPredictionsPlot, color=\"tab:red\", label=\"predictions data\", linewidth=2)\n",
    "\n",
    "# membuat label-label\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "37197ad202cea1caf8a636a74cec7c83b945e4f29ac1505900600f740c02611d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
